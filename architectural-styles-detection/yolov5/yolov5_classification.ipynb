{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GYQX3of4QiW"
   },
   "source": [
    "# Тренировка классификационной модели YOLOv5\n",
    "Способ fine-tuning модели YOLOv5 и обучение за пределами Roboflow.\n",
    "\n",
    "**Здесь используется:**\n",
    "1. Модель классификации [YOLOv5](https://github.com/ultralytics/yolov5)\n",
    "2. Размеченный, аугументированный и разбитый на train/test/valid датасет Roboflow\n",
    "3. API-интерфейс Roboflow для получения датасета.\n",
    "4. Подключение Google Drive для сохранения результатов обучения, валидации и предсказаний модели.\n",
    "\n",
    "\n",
    "**Порядок реализации:**\n",
    "1. Установка и подключение необходимых библиотек и модулей\n",
    "2. Тренировка на произвольных данных\n",
    "   1. Установка модуля Roboflow и загрузка датасета\n",
    "   2. Тренировка модели YOLOv5\n",
    "   3. Копирование результатов в Google Drive\n",
    "3. Валидация модели (на валидационных данных)\n",
    "4. Предсказание по произвольным изображениям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PJ8vlYXbWtN"
   },
   "source": [
    "## 1. Установка необходимых библиотек и модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33893,
     "status": "ok",
     "timestamp": 1734473302096,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "pIM7fOwm8A7l",
    "outputId": "2bdb4baf-7ec6-4da6-e22d-6102ffe27887"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.7/112.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bXHHYeVDCXg"
   },
   "source": [
    "## 2. Тренировка на произвольных данных\n",
    "\n",
    "Для тренировки модели, необходимо подготовить размеченный датасет.\n",
    "\n",
    "Для подготовки датасета мы использовали [Roboflow](https://roboflow.com).\n",
    "\n",
    "Ссылка на датасет: [https://universe.roboflow.com/mipt4/archistyles/dataset/1](https://universe.roboflow.com/mipt4/archistyles/dataset/1)\n",
    "\n",
    "\n",
    "> Здесь можно найти подробную инструкцию по [тренировке YOLOv5 классификации на произвольных данных](https://blog.roboflow.com/train-YOLOv5-classification-custom-data).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cu6-lrukD6Hc"
   },
   "source": [
    "### 2.1. Загружаем датасет\n",
    "\n",
    "Структура данных в датасете из изображений должна быть такой:\n",
    "\n",
    "```\n",
    "dataset\n",
    "├── train\n",
    "│   ├── class-one\n",
    "│   │   ├── IMG_123.jpg\n",
    "│   └── class-two\n",
    "│       ├── IMG_456.jpg\n",
    "├── valid\n",
    "│   ├── class-one\n",
    "│   │   ├── IMG_789.jpg\n",
    "│   └── class-two\n",
    "│       ├── IMG_101.jpg\n",
    "├── test\n",
    "│   ├── class-one\n",
    "│   │   ├── IMG_121.jpg\n",
    "│   └── class-two\n",
    "│       ├── IMG_341.jpg\n",
    "```\n",
    "\n",
    "Структура датасета, созданного нами в Roboflow выглядит так:\n",
    "![](https://j.leadzilla.ru/train-test-valid.jpg)\n",
    "\n",
    "![](https://i.imgur.com/BF9BNR8.gif)\n",
    "\n",
    "\n",
    "\n",
    "Забираем код сниппета из [Робофлоу](https://universe.roboflow.com/mipt4/archistyles/dataset/1) чтобы загрузить датасет в контейнер Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1734475192052,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "6IIgJbP7G6Th",
    "outputId": "2f5f1060-0472-4294-9930-2996b59729fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datasets\n"
     ]
    }
   ],
   "source": [
    "# Создаем и переходим в директорию для загрузки датасета\n",
    "import os\n",
    "os.makedirs(\"/content/datasets/\", exist_ok=True)\n",
    "%cd /content/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1733872146434,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "OfVS1fpR0NYq",
    "outputId": "e1003650-5314-4887-bbd4-5441cffdc0f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datasets\n",
      "/content/datasets\n"
     ]
    }
   ],
   "source": [
    "# Вспомогательный код, чтобы убедиться, что работаешь в правильной папке\n",
    "# %cd ../datasets/\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28675,
     "status": "ok",
     "timestamp": 1734475227270,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "He6JwHIlG-W_",
    "outputId": "82e7c0e1-5a95-4d7c-f3dc-5ba4173dcd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.50-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
      "Downloading roboflow-1.1.50-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: filetype, python-dotenv, idna, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 roboflow-1.1.50\n",
      "Датасет не найден локально. Загружаем с Roboflow...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in ArchiStyles-1 to folder:: 100%|██████████| 891975/891975 [00:18<00:00, 48803.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to ArchiStyles-1 in folder:: 100%|██████████| 10653/10653 [00:03<00:00, 2966.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имя датасета сохранено в переменную окружения: ArchiStyles-1\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем робофлоу\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "from google.colab import userdata\n",
    "\n",
    "# Путь, где должен находиться локальный датасет\n",
    "local_dataset_path = \"/content/datasets/ArchiStyles-1\"\n",
    "\n",
    "if not os.path.exists(local_dataset_path):\n",
    "    # Если папки нет, загружаем датасет с Roboflow\n",
    "    print(\"Датасет не найден локально. Загружаем с Roboflow...\")\n",
    "    # Вместо userdata.get('roboflow_secret') используйте свой ключ API Roboflow\n",
    "    # Следующие 4 строки кода из сниппета (Download Dataset) Roboflow\n",
    "    rf = Roboflow(api_key=userdata.get('roboflow_secret'))\n",
    "    project = rf.workspace(\"mipt4\").project(\"archistyles\")\n",
    "    version = project.version(1)\n",
    "    dataset = version.download(\"folder\")\n",
    "    dataset_name = dataset.location.split(os.sep)[-1]  # Имя папки с датасетом\n",
    "else:\n",
    "    # Если папка есть, просто используем её\n",
    "    print(f\"Датасет найден локально: {local_dataset_path}\")\n",
    "    dataset_name = os.path.basename(local_dataset_path)  # Имя папки с датасетом\n",
    "\n",
    "# Сохраняем имя датасета в переменную окружения DATASET_NAME\n",
    "os.environ[\"DATASET_NAME\"] = dataset_name\n",
    "\n",
    "print(f\"Имя датасета сохранено в переменную окружения: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5z7Yv42FGrK"
   },
   "source": [
    "### 2.2 Тренируем модель и сохраняем результаты 🎉\n",
    "Здесь мы используем переменную окружения `DATASET_NAME` чтобы передать наш датасет в параметр `--data` модели.\n",
    "\n",
    "> Заметка: здесь мы тренируем модель на 100 эпохах. Также мы используем для старта обучения предтренировочные веса модели YOLOv5. В дальнейшем мы сможем использовать веса результатов уже наших тренировок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8u5cjJ6BNc_"
   },
   "source": [
    "### 2.2.1. Подготовка к сохранению результатов обучения модели\n",
    "\n",
    "Поскольку Collab стирает все данные при остановке контейнера, мы скопируем результаты обучения на гугл-диск. Для этого:\n",
    "1. Даем Collab доступ к гугл-диску.\n",
    "2. Задаем путь к папке сохранения результатов.\n",
    "3. Создаем название папки для сохранения текущего обучения модели\n",
    "4. По результату обучения модели копируем результаты обучения из контейнера Collab в создаваемую на этапе 3 папку на гугл-диске.\n",
    "\n",
    "\n",
    "При завершении обучения YOLOv5 результаты обучения модели будут находятся в папке Collab:\n",
    "\n",
    "`content/yolov5/runs/train-cls/exp#`,\n",
    "\n",
    "где `#` - порядковый номер обучения модели). По результату обучения модели мы сохраним их на Google Диске, чтобы коллаб не стер их при остановке контейнера.\n",
    "\n",
    "### 2.2.2. Подключение к Google Drive и задание пути к папке результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24172,
     "status": "ok",
     "timestamp": 1734473947903,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "joESqV4QEc7u",
    "outputId": "cf59e68c-ad42-4867-9119-1bf9abe0ad11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Подключаем гугл-диск для подгрузки данных предыдущих обучений и сохранения\n",
    "новых результатов.\n",
    "Ваш гугл-диск будет подключен и синхронизирован с папкой '/content/drive'\n",
    "этого контейнера Collab\n",
    "'''\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive') # путь к папке в контейнере Collab\n",
    "# При первом запуске нужно будет разрешить Коллабу доступ к Google Drive\n",
    "\n",
    "'''\n",
    "  Задайте путь к папке сохранения результатов на вашем Google Drive\n",
    "  Сохранять нужно сюда: https://drive.google.com/drive/folders/1BfsY5-UEowLiEO6N5yB0mq_B2ZrfeIhh?usp=drive_link\n",
    "  Часть пути \"MyDrive/!!! Data Science/Хакатоны/\" у вас будет свой\n",
    "'''\n",
    "results_dir = \"/content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results\"\n",
    "\n",
    "# проверка корректности пути к папке results_dir\n",
    "print(os.path.exists(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1733944280858,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "MHbxSEnlIK03",
    "outputId": "136da7bc-f0ff-4e1f-96bb-7f241b42fbbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вспомогательный код\n",
    "# os.path.exists(results_dir) # проверка папки на существование, корректность пути\n",
    "# print(os.getcwd()) # проверка в какой мы папке сейчас\n",
    "# os.listdir() # вывести содержимое текущей папки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhMlH4BFuF3D"
   },
   "source": [
    "### 2.2.3. Создание функции генерации имени новой папки сохранения и функций копирования результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMYYM0F0Dl8m"
   },
   "outputs": [],
   "source": [
    "# !pip install pytz # для задания МСК часового пояса\n",
    "import shutil\n",
    "import os\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def save_result_dir_name(results_dir, params):\n",
    "  '''\n",
    "  Функция генерирует название для папки на основе параметров обучения.\n",
    "  @results_dir - путь к папке результатов на гугл-диске\n",
    "  @params - нужно передать словарь с параметрами обучения модели:\n",
    "    batch_size, lr, img, epochs, optimizer\n",
    "  returns: string - возвращает путь к папке сохранения результатов обучения\n",
    "  '''\n",
    "  # Создаем временную зону UTC+3\n",
    "  utc_plus_3 = pytz.timezone(\"Europe/Moscow\")  # UTC+3, соответствует Москве\n",
    "  # Получаем текущее время с учётом часового пояса\n",
    "  current_time = datetime.now(utc_plus_3)\n",
    "\n",
    "  timestamp = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "  # Создаем название папки на основе параметров обучения модели: время старта + гиперпараметры\n",
    "  experiment_params = f\"{timestamp} batch-size {params['batch_size']} lr {params['lr']} img {params['img']} epochs {params['epochs']} optimizer {params['optimizer']}\"\n",
    "  return os.path.join(results_dir, experiment_params)\n",
    "\n",
    "\n",
    "def copy_model_run_result(run_type, to_path):\n",
    "  '''\n",
    "  Функция копирования папки результата работы модели в папку to_path\n",
    "  @run_type - тип запуска модели: train или val\n",
    "  @to_path - путь сохранения результатов\n",
    "  '''\n",
    "  from_path = f'/content/yolov5/runs/{run_type}-cls/'\n",
    "  if os.path.exists(from_path):\n",
    "    os.chdir(from_path)\n",
    "    # Копируем папку с последним результатом\n",
    "    last_run = from_path + os.listdir()[-1]\n",
    "    shutil.copytree(os.path.join(last_run), os.path.join(to_path))\n",
    "  else:\n",
    "    print(f'Папка {from_path} еще не создана. Сперва отработайте модель.')\n",
    "\n",
    "# Функция копирования файла\n",
    "def copy_file(from_path, to_path):\n",
    "    if os.path.isfile(from_path):  # Проверяем, что путь указывает на файл\n",
    "        # Создаём целевую папку, если она не существует\n",
    "        os.makedirs(to_path, exist_ok=True)\n",
    "\n",
    "        # Копируем файл в целевую папку\n",
    "        destination_path = os.path.join(to_path, os.path.basename(from_path))\n",
    "        shutil.copy(from_path, destination_path)\n",
    "\n",
    "        print(f\"Файл {from_path} успешно скопирован в {destination_path}\")\n",
    "    else:\n",
    "        print(f\"Файл {from_path} не найден. Проверьте путь и запустите модель.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V4mYcGCuRTZ"
   },
   "source": [
    "### 2.2.4. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXWTTN2BEaqe",
    "outputId": "a321da35-5eae-422e-8fca-3c200b8795f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл /content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results/2024-12-17 13:08:23 batch-size 64 lr 0.001 img 128 epochs 100 optimizer Adam/weights/best.pt успешно скопирован в /content/yolov5/runs/train-cls/best/best.pt\n",
      "/content/yolov5\n",
      "Запуск обучения...\n",
      "2024-12-18 00:37:27.858311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-18 00:37:27.890379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-18 00:37:27.896981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, data=ArchiStyles-1, epochs=50, batch_size=64, imgsz=300, nosave=False, cache=None, device=0, workers=8, project=runs/train-cls, name=exp, exist_ok=True, pretrained=/content/yolov5/runs/train-cls/best/best.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, size=(300, 300), scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1, mask_interpolation=0), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(0.0, 0.0)), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, normalization='standard'), ToTensorV2(p=1.0, transpose_mask=False)\n",
      "Model summary: 149 layers, 4186571 parameters, 4186571 gradients, 10.5 GFLOPs\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 32 weight(decay=0.0), 33 weight(decay=5e-05), 33 bias\n",
      "/content/yolov5/classify/train.py:201: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=cuda)\n",
      "Image sizes 300 train, 300 test\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp\u001b[0m\n",
      "Starting yolov5s-cls.pt training on ArchiStyles-1 dataset with 11 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n",
      "  0% 0/143 [00:00<?, ?it/s]/content/yolov5/classify/train.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(enabled=cuda):  # stability issues when enabled\n",
      "      1/50      2.5G        2.32                             testing:   0% 0/4 [00:00<?, ?it/s]/content/yolov5/classify/val.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type != \"cpu\"):\n",
      "      1/50      2.5G        2.32        2.28       0.221       0.645: 100% 143/143 [01:11<00:00,  2.01it/s]\n",
      "      2/50     2.96G        2.23        2.73       0.159       0.602: 100% 143/143 [01:07<00:00,  2.13it/s]\n",
      "      3/50     2.96G        2.24                                    :   6% 9/143 [00:04<01:11,  1.87it/s]"
     ]
    }
   ],
   "source": [
    "# Копируем лучшие веса в папку Коллаба 'runs/train-cls/best/best.pt'\n",
    "# Тут нужно указать путь к лучшим весам на гугл-диске\n",
    "best_weights_file = '/content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results/2024-12-17 13:08:23 batch-size 64 lr 0.001 img 128 epochs 100 optimizer Adam/weights/best.pt'\n",
    "to_dir = '/content/yolov5/runs/train-cls/best'\n",
    "copy_file(best_weights_file, to_dir)\n",
    "\n",
    "# Задаем гиперпараметры обучения модели\n",
    "# Можем использовать файл наших лучших весов\n",
    "best_weights = ''\n",
    "params = {\n",
    "  \"batch_size\": 64,\n",
    "  \"lr\": 0.001,\n",
    "  \"img\": 300,\n",
    "  \"epochs\": 50,\n",
    "  \"workers\": 8,\n",
    "  \"device\": 0,\n",
    "  # \"pretrained_weights\": \"weights/yolov5s-cls.pt\", # начальные веса YOLOv5\n",
    "  \"pretrained_weights\": \"/content/yolov5/runs/train-cls/best/best.pt\", # наши\n",
    "  \"optimizer\": \"Adam\"\n",
    "}\n",
    "\n",
    "# Переходим в папку yolov5 и стартуем обучение\n",
    "%cd /content/yolov5\n",
    "\n",
    "# Сборка команды как строки\n",
    "command = (\n",
    "    f\"python classify/train.py \"\n",
    "    f\"--model yolov5s-cls.pt \"\n",
    "    f\"--data $DATASET_NAME \"\n",
    "    f\"--epochs {params['epochs']} \"\n",
    "    f\"--img {params['img']} \"\n",
    "    f\"--batch-size {params['batch_size']} \"\n",
    "    f\"--lr {params['lr']} \"\n",
    "    f\"--exist-ok \" # Перезаписывает папку exp новыми результатами\n",
    "    f\"--device {params['device']} \"\n",
    "    f\"--workers {params['workers']} \"\n",
    "    f\"--optimizer {params['optimizer']} \"\n",
    "    f\"--pretrained {params['pretrained_weights']}\"\n",
    ")\n",
    "\n",
    "# Выполнение команды обучения\n",
    "print(\"Запуск обучения...\")\n",
    "!{command}\n",
    "\n",
    "# Создаем название папки для сохранения результатов обучения\n",
    "save_res_dir = save_result_dir_name(results_dir, params)\n",
    "# Копируем в нее результаты тренировки\n",
    "copy_model_run_result(run_type='train', to_path=save_res_dir)\n",
    "print(f\"Результаты скопированы в {save_res_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHUFGeLbGd98"
   },
   "source": [
    "## 3. Валидация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11193,
     "status": "ok",
     "timestamp": 1734481000575,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "DIV7ydyKGZFL",
    "outputId": "f2b18574-1e0f-4402-eba0-aea54301eb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл /content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results/2024-12-17 13:08:23 batch-size 64 lr 0.001 img 128 epochs 100 optimizer Adam/weights/best.pt успешно скопирован в /content/yolov5/runs/train-cls/best/best.pt\n",
      "/content/yolov5\n",
      "Запуск валидации...\n",
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/content/datasets/ArchiStyles-1, weights=['runs/train-cls/exp/weights/best.pt'], batch_size=128, imgsz=224, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 117 layers, 4180779 parameters, 0 gradients, 10.4 GFLOPs\n",
      "testing:   0% 0/4 [00:00<?, ?it/s]/content/yolov5/classify/val.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type != \"cpu\"):\n",
      "testing: 100% 4/4 [00:03<00:00,  1.16it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all         498       0.181       0.647\n",
      "             Art Nouveau          74       0.757       0.932\n",
      "                 Baroque          55           0           1\n",
      "              Beaux-Arts          53           0           1\n",
      "               Byzantine          40           0           0\n",
      "          Chicago school          18           0           0\n",
      "        Deconstructivism          41           0       0.732\n",
      "               Edwardian          18           0           0\n",
      "                  Gothic          53           0       0.415\n",
      "               Palladian          44           0       0.409\n",
      "              Postmodern          52         0.5       0.673\n",
      "              Romanesque          50        0.16         0.8\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.2ms post-process per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/val-cls/exp9\u001b[0m\n",
      "Валидация завершена\n",
      "Результаты скопированы в /content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results/2024-12-18 03:09:02 batch-size 64 lr 0.001 img 128 epochs 3 optimizer Adam\n"
     ]
    }
   ],
   "source": [
    "# Копируем лучшие веса в папку Коллаба 'runs/train-cls/best/best.pt'\n",
    "# Тут нужно указать путь к лучшим весам на гугл-диске\n",
    "best_weights_file = '/content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results/2024-12-17 13:08:23 batch-size 64 lr 0.001 img 128 epochs 100 optimizer Adam/weights/best.pt'\n",
    "to_dir = '/content/yolov5/runs/train-cls/best'\n",
    "copy_file(best_weights_file, to_dir)\n",
    "\n",
    "# Переходим в папку yolov5 и стартуем валидацию\n",
    "%cd /content/yolov5\n",
    "\n",
    "# Задаем параметры валидации\n",
    "# weights = 'runs/train-cls/best/best.pt' # путь к нашим весам для валидации\n",
    "weights = 'runs/train-cls/exp/weights/best.pt' # путь к последним весам\n",
    "dataset = '/content/datasets/$DATASET_NAME' # путь к датасету\n",
    "\n",
    "# Сборка команды\n",
    "command = (\n",
    "    f\"python classify/val.py \"\n",
    "    f\"--weights {weights} \"\n",
    "    f\"--data {dataset}\"\n",
    ")\n",
    "\n",
    "# Выполнение команды обучения\n",
    "print(\"Запуск валидации...\")\n",
    "!{command}\n",
    "print(\"Валидация завершена\")\n",
    "\n",
    "# Сохраняем результаты валидации в save_res_dir или custom_dir\n",
    "custom_dir = '/content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/results/2024-12-17 13:08:23 batch-size 64 lr 0.001 img 128 epochs 100 optimizer Adam'\n",
    "copy_model_run_result(run_type='val', to_path = save_res_dir + '/val')\n",
    "print(f\"Результаты скопированы в {save_res_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH5tJNpEsi6g"
   },
   "source": [
    "## 4. Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1734481698461,
     "user": {
      "displayName": "Олег Рассказов",
      "userId": "06671603455380682613"
     },
     "user_tz": -60
    },
    "id": "81lK1hU_sk54",
    "outputId": "f3a67ff2-d056-4ce3-a939-49cf8edc8830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл /content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/images/roman_building.jpg успешно скопирован в /content/yolov5/runs/predict/roman_building.jpg\n",
      "/content/yolov5\n",
      "Запуск предсказания...\n",
      "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['runs/train-cls/best/best.pt'], source=/content/yolov5/runs/predict/roman_building.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 117 layers, 4180779 parameters, 0 gradients, 10.4 GFLOPs\n",
      "image 1/1 /content/yolov5/runs/predict/roman_building.jpg: 224x224 Romanesque 0.75, Gothic 0.07, Byzantine 0.04, Beaux-Arts 0.02, Postmodern 0.02, 3.0ms\n",
      "Speed: 0.3ms pre-process, 3.0ms inference, 26.1ms NMS per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/predict-cls/exp2\u001b[0m\n",
      "Предсказание готово\n"
     ]
    }
   ],
   "source": [
    "# Копируем тестовую картинку в папку Коллаба 'runs/predict'\n",
    "img_name = 'roman_building.jpg'\n",
    "img_path = '/content/drive/MyDrive/!!! Data Science/Хакатоны/1_architectural_styles/images/'\n",
    "to_dir = '/content/yolov5/runs/predict'\n",
    "copy_file(img_path+img_name, to_dir)\n",
    "\n",
    "# Путь к картинке, которую предсказываем\n",
    "test_img = f'{to_dir}/{img_name}'\n",
    "# Зададим веса для предсказания\n",
    "weights = 'runs/train-cls/best/best.pt' # путь к нашим весам для валидации\n",
    "# weights = 'runs/train-cls/exp/weights/best.pt'\n",
    "\n",
    "# Сборка команды\n",
    "command = (\n",
    "    f\"python classify/predict.py \"\n",
    "    f\"--weights {weights} \"\n",
    "    f\"--source {test_img}\"\n",
    ")\n",
    "\n",
    "# Переходим в папку yolov5 и стартуем предсказание\n",
    "%cd /content/yolov5\n",
    "print(\"Запуск предсказания...\")\n",
    "!{command}\n",
    "print(\"Предсказание готово\")\n",
    "\n",
    "# Сохраняем результаты предсказания\n",
    "copy_model_run_result(run_type='predict', to_path = save_res_dir + '/predict')\n",
    "print(f\"Результаты скопированы в {save_res_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdGuG-1kNjWT"
   },
   "source": [
    "We can see the inference results show ~3ms inference and the respective classes predicted probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I38IM6NXKNN9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## (Опционально) Улучшение модели с помощью активного обучения\n",
    "\n",
    "Now that we've trained our model once, we will want to continue to improve its performance. Improvement is largely dependent on improving our dataset.\n",
    "\n",
    "We can programmatically upload example failure images back to our custom dataset based on conditions (like seeing an underrpresented class or a low confidence score) using the same `pip` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HycgSEnYKo0J"
   },
   "outputs": [],
   "source": [
    "# # Upload example image\n",
    "# project.upload(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwXDoz_vLK3V"
   },
   "outputs": [],
   "source": [
    "# # Example upload code\n",
    "# min_conf = float(\"inf\")\n",
    "# for pred in results:\n",
    "#     if pred[\"score\"] < min_conf:\n",
    "#         min_conf = pred[\"score\"]\n",
    "# if min_conf < 0.4:\n",
    "#     project.upload(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKSP-SNTvcLJ"
   },
   "source": [
    "###Directory Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwSoHcHcvjeD"
   },
   "outputs": [],
   "source": [
    "#Directory infer\n",
    "os.environ[\"TEST_CLASS_PATH\"] = test_class_path = os.path.join(*os.environ[\"TEST_IMAGE_PATH\"].split(os.sep)[:-1])\n",
    "print(f\"Infering on all images from the directory {os.environ['TEST_CLASS_PATH']}\")\n",
    "!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source /$TEST_CLASS_PATH/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "12uGWYB82g6fd4JKGgHRcmPKGOsbUsN4p",
     "timestamp": 1734482401692
    },
    {
     "file_id": "1KZiKUAjtARHAfZCXbJRv14-pOnIsBLPV",
     "timestamp": 1733851725477
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
